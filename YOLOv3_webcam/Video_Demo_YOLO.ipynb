{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T08:49:14.452295Z",
     "start_time": "2020-12-21T08:49:13.817228Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "from models import *\n",
    "from utils.utils import *\n",
    "from utils.datasets import *\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "import argparse\n",
    "import cv2\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.ticker import NullLocator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arg Parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T08:49:14.455791Z",
     "start_time": "2020-12-21T08:49:14.453284Z"
    }
   },
   "outputs": [],
   "source": [
    "class opt:\n",
    "    image_folder = \"data/samples\"\n",
    "    model_def = \"config/yolov3.cfg\"\n",
    "    weights_path = \"weights/yolov3.weights\"\n",
    "    class_path = \"data/coco.names\"\n",
    "    conf_thres = 0.8\n",
    "    nms_thres = 0.4\n",
    "    batch_size = 1\n",
    "    n_cpu = 0\n",
    "    img_size = 416\n",
    "    checkpoint_model= str()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T08:49:14.469305Z",
     "start_time": "2020-12-21T08:49:14.456283Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_one_box(x, img, color=1, label=None, line_thickness=None):\n",
    "    # Plots one bounding box on image img\n",
    "    tl = line_thickness or round(0.002 * (img.shape[0] + img.shape[1]) / 2) + 1  # line/font thickness\n",
    "    color = color or [random.randint(0, 255) for _ in range(3)]\n",
    "    c1, c2 = (int(x[0]), int(x[1])), (int(x[2]), int(x[3]))\n",
    "    cv2.rectangle(img, c1, c2, color, thickness=tl, lineType=cv2.LINE_AA)\n",
    "    if label:\n",
    "        tf = max(tl - 1, 1)  # font thickness\n",
    "        t_size = cv2.getTextSize(label, 0, fontScale=tl / 3, thickness=tf)[0]\n",
    "        c2 = c1[0] + t_size[0], c1[1] - t_size[1] - 3\n",
    "        cv2.rectangle(img, c1, c2, color, -1, cv2.LINE_AA)  # filled\n",
    "        cv2.putText(img, label, (c1[0], c1[1] - 2), 0, tl / 3, [225, 255, 255], thickness=tf, lineType=cv2.LINE_AA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T08:49:14.473307Z",
     "start_time": "2020-12-21T08:49:14.470305Z"
    }
   },
   "outputs": [],
   "source": [
    "def figure_to_array(fig):\n",
    "    \"\"\"\n",
    "    plt.figure를 RGBA로 변환(layer가 4개)\n",
    "    shape: height, width, layer\n",
    "    \"\"\"\n",
    "    fig.canvas.draw()\n",
    "    return np.array(fig.canvas.renderer._renderer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T08:49:16.131097Z",
     "start_time": "2020-12-21T08:49:14.474305Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "os.makedirs(\"output\", exist_ok=True)\n",
    "\n",
    "# Set up model\n",
    "model = Darknet(opt.model_def, img_size=opt.img_size).to(device)\n",
    "\n",
    "if opt.weights_path.endswith(\".weights\"):\n",
    "    # Load darknet weights\n",
    "    model.load_darknet_weights(opt.weights_path)\n",
    "else:\n",
    "    # Load checkpoint weights\n",
    "    model.load_state_dict(torch.load(opt.weights_path))\n",
    "\n",
    "model.eval()  # Set in evaluation mode\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    ImageFolder(opt.image_folder, img_size=opt.img_size),\n",
    "    batch_size=opt.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=opt.n_cpu,\n",
    ")\n",
    "\n",
    "classes = load_classes(opt.class_path)  # Extracts class labels from file\n",
    "\n",
    "Tensor = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor\n",
    "\n",
    "imgs = []  # Stores image paths\n",
    "img_detections = []  # Stores detections for each image index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T08:49:16.146018Z",
     "start_time": "2020-12-21T08:49:16.131097Z"
    }
   },
   "outputs": [],
   "source": [
    "cam = cv2.VideoCapture('./../drive_fornt_sample.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T08:49:38.898884Z",
     "start_time": "2020-12-21T08:49:16.147018Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPS of the video is  0.41\n",
      "[tensor([[ 66.4197, 257.0344, 131.2004, 307.3551,   0.9992,   0.9997,   2.0000],\n",
      "        [322.4802, 234.2759, 416.0887, 387.4740,   0.9978,   0.9992,   2.0000],\n",
      "        [140.2990, 260.5547, 168.8712, 290.4017,   0.9989,   0.9965,   2.0000],\n",
      "        [ -1.5365, 241.5591,  79.9595, 334.4342,   0.9966,   0.9950,   2.0000],\n",
      "        [226.9790, 265.3445, 251.6054, 293.7183,   0.9679,   0.9848,   2.0000],\n",
      "        [164.0794, 261.5971, 183.1074, 285.9209,   0.9564,   0.9916,   2.0000],\n",
      "        [202.0893, 262.3770, 217.6646, 284.5333,   0.9669,   0.9474,   2.0000],\n",
      "        [192.1325, 262.9680, 200.4778, 278.9627,   0.8471,   0.9935,   2.0000],\n",
      "        [216.4868, 263.6098, 225.4986, 279.3086,   0.8496,   0.9614,   2.0000]])]\n",
      "FPS of the video is  6.82\n",
      "[tensor([[ 20.9890, 252.3455, 112.7417, 320.1380,   0.9935,   0.9966,   2.0000],\n",
      "        [128.4338, 257.9867, 161.0182, 292.7920,   0.9971,   0.9876,   2.0000],\n",
      "        [323.0310, 236.8269, 415.1489, 362.6141,   0.9989,   0.9649,   2.0000],\n",
      "        [227.1333, 263.9545, 252.1405, 293.2715,   0.9610,   0.9900,   2.0000],\n",
      "        [152.7257, 257.6858, 178.4125, 287.5589,   0.9615,   0.9890,   2.0000],\n",
      "        [  0.8665, 264.0834,  25.3550, 344.2111,   0.9557,   0.9801,   2.0000],\n",
      "        [190.8369, 262.2688, 199.8727, 277.5974,   0.9371,   0.9986,   2.0000],\n",
      "        [200.1057, 261.7831, 217.5423, 284.3182,   0.9569,   0.9743,   2.0000],\n",
      "        [214.4581, 261.4682, 224.6751, 278.5820,   0.8908,   0.9708,   2.0000]])]\n",
      "FPS of the video is 11.85\n",
      "[tensor([[ 85.5811, 258.9379, 137.3655, 303.7938,   0.9983,   0.9980,   2.0000],\n",
      "        [301.1049, 250.0852, 400.6763, 325.7739,   0.9992,   0.9904,   2.0000],\n",
      "        [128.3983, 255.6196, 163.6474, 294.7656,   0.9928,   0.9687,   2.0000],\n",
      "        [227.7766, 266.6194, 252.0859, 294.6471,   0.9644,   0.9950,   2.0000],\n",
      "        [194.6281, 261.6182, 214.1141, 286.8942,   0.9646,   0.9916,   2.0000],\n",
      "        [160.7289, 259.4269, 182.4231, 287.1858,   0.9329,   0.9949,   2.0000],\n",
      "        [178.8578, 261.7368, 194.7760, 280.7213,   0.8897,   0.9927,   2.0000],\n",
      "        [211.3419, 260.4142, 224.6303, 280.7784,   0.9318,   0.9417,   2.0000]])]\n",
      "FPS of the video is 30.33\n",
      "[tensor([[2.7879e+02, 2.5453e+02, 3.2985e+02, 3.0748e+02, 9.9909e-01, 9.8929e-01,\n",
      "         2.0000e+00],\n",
      "        [1.3955e+02, 2.5935e+02, 1.6616e+02, 2.9069e+02, 9.8792e-01, 9.9432e-01,\n",
      "         2.0000e+00],\n",
      "        [2.2600e+02, 2.6656e+02, 2.5001e+02, 2.9257e+02, 9.8431e-01, 9.9756e-01,\n",
      "         2.0000e+00],\n",
      "        [1.4129e-01, 2.3710e+02, 8.9741e+01, 3.3254e+02, 9.9946e-01, 9.6835e-01,\n",
      "         2.0000e+00],\n",
      "        [1.8143e+02, 2.6288e+02, 2.0581e+02, 2.9240e+02, 9.9573e-01, 9.5982e-01,\n",
      "         2.0000e+00],\n",
      "        [9.9873e+01, 2.5359e+02, 1.4242e+02, 3.0419e+02, 9.7281e-01, 9.7899e-01,\n",
      "         2.0000e+00],\n",
      "        [2.0342e+02, 2.6065e+02, 2.1954e+02, 2.8301e+02, 9.1706e-01, 9.8786e-01,\n",
      "         2.0000e+00]])]\n",
      "FPS of the video is 30.36\n",
      "[tensor([[194.1259, 259.8431, 215.9544, 284.4510,   0.9848,   0.9954,   2.0000],\n",
      "        [163.3190, 260.3496, 196.1075, 297.9374,   0.9986,   0.9766,   2.0000],\n",
      "        [ 17.8065, 246.9254,  93.8968, 320.0182,   0.9974,   0.9738,   2.0000],\n",
      "        [264.5339, 260.2847, 297.7807, 296.9654,   0.9943,   0.9745,   2.0000],\n",
      "        [128.3782, 260.9522, 159.5863, 291.9098,   0.9652,   0.9937,   2.0000],\n",
      "        [221.3400, 269.9536, 244.0727, 294.5855,   0.9583,   0.9898,   2.0000],\n",
      "        [ 88.3146, 251.7802, 131.6473, 300.6489,   0.9949,   0.8471,   2.0000]])]\n",
      "FPS of the video is 12.81\n",
      "[tensor([[ 85.7573, 260.7252, 136.8071, 305.2799,   0.9961,   0.9988,   2.0000],\n",
      "        [156.3970, 259.9001, 194.1556, 302.7477,   0.9990,   0.9901,   2.0000],\n",
      "        [260.2165, 266.2815, 290.2560, 294.7731,   0.9965,   0.9891,   2.0000],\n",
      "        [192.6067, 262.6571, 214.8230, 286.6596,   0.9893,   0.9901,   2.0000],\n",
      "        [220.6968, 269.5016, 243.1466, 295.4688,   0.9719,   0.9928,   2.0000],\n",
      "        [  4.2783, 238.6590,  90.0611, 322.8965,   0.9969,   0.9125,   2.0000]])]\n",
      "FPS of the video is 14.91\n",
      "[tensor([[ -1.4767, 252.9330,  85.6925, 324.9765,   0.9986,   0.9915,   2.0000],\n",
      "        [139.1225, 264.7009, 155.9553, 290.4006,   0.9871,   0.9953,   2.0000],\n",
      "        [151.0243, 264.8160, 192.8792, 309.0249,   0.9977,   0.9839,   2.0000],\n",
      "        [258.6789, 266.6176, 282.3431, 293.7076,   0.9951,   0.9827,   2.0000],\n",
      "        [221.1008, 269.5089, 242.7486, 295.2415,   0.9813,   0.9875,   2.0000],\n",
      "        [193.4975, 264.9395, 215.2468, 287.2771,   0.9640,   0.9730,   2.0000]])]\n",
      "FPS of the video is  5.89\n",
      "[tensor([[ -1.1806, 248.6104,  53.9743, 332.5943,   0.9954,   0.9952,   2.0000],\n",
      "        [149.7074, 260.6692, 193.3443, 308.3177,   0.9992,   0.9870,   2.0000],\n",
      "        [258.6592, 266.7361, 280.7977, 292.0819,   0.9970,   0.9854,   2.0000],\n",
      "        [130.0296, 260.7026, 154.9244, 292.5872,   0.9816,   0.9876,   2.0000],\n",
      "        [197.6171, 260.5646, 215.5981, 284.3824,   0.9807,   0.9862,   2.0000],\n",
      "        [221.7410, 268.2213, 241.9454, 293.0639,   0.9663,   0.9893,   2.0000],\n",
      "        [190.2622, 266.3856, 198.3119, 281.9146,   0.8124,   0.9980,   2.0000]])]\n",
      "FPS of the video is 16.84\n",
      "[tensor([[143.5858, 259.3864, 190.0520, 310.4164,   0.9993,   0.9955,   2.0000],\n",
      "        [256.3654, 265.0005, 277.6198, 288.6956,   0.9948,   0.9933,   2.0000],\n",
      "        [ 77.8311, 257.8954, 137.3521, 303.4283,   0.9994,   0.9842,   2.0000],\n",
      "        [200.5025, 260.0068, 217.7994, 283.8712,   0.9666,   0.9874,   2.0000],\n",
      "        [223.2984, 266.1696, 243.1319, 291.9558,   0.9493,   0.9797,   2.0000],\n",
      "        [126.3164, 258.4072, 148.2416, 294.0417,   0.8433,   0.9950,   2.0000]])]\n",
      "FPS of the video is  8.97\n",
      "[tensor([[133.8163, 256.8200, 188.7061, 313.5176,   0.9999,   0.9978,   2.0000],\n",
      "        [ -0.5594, 253.0046,  97.1242, 322.3757,   0.9997,   0.9971,   2.0000],\n",
      "        [ 84.3995, 258.0898, 137.0930, 304.7552,   0.9966,   0.9984,   2.0000],\n",
      "        [255.0138, 264.6236, 273.7904, 285.6321,   0.9889,   0.9942,   2.0000],\n",
      "        [224.2398, 266.3709, 243.3761, 290.9583,   0.9763,   0.9764,   2.0000],\n",
      "        [201.1960, 259.3693, 218.1228, 284.3085,   0.9578,   0.9699,   2.0000],\n",
      "        [189.8032, 265.3460, 200.5712, 281.5129,   0.8355,   0.9988,   2.0000]])]\n",
      "FPS of the video is 10.24\n",
      "[tensor([[128.4840, 253.6905, 190.0971, 321.0609,   0.9975,   0.9793,   2.0000],\n",
      "        [ -2.5031, 255.9257,  92.2971, 331.0922,   0.9860,   0.9829,   2.0000],\n",
      "        [255.2211, 265.9774, 272.7857, 286.3370,   0.9820,   0.9861,   2.0000],\n",
      "        [ 91.4543, 259.5079, 131.6342, 305.0729,   0.9776,   0.9852,   2.0000],\n",
      "        [225.2822, 268.6137, 244.9612, 291.8611,   0.9734,   0.9832,   2.0000],\n",
      "        [202.5263, 264.0180, 219.0033, 285.6741,   0.9429,   0.8974,   2.0000],\n",
      "        [184.5061, 268.8006, 196.9988, 284.5129,   0.8125,   0.9986,   2.0000]])]\n",
      "FPS of the video is  3.68\n",
      "[tensor([[ 69.6968, 261.9654, 123.8162, 312.4143,   0.9995,   0.9981,   2.0000],\n",
      "        [ -0.4422, 255.0227,  69.6324, 343.3038,   0.9987,   0.9906,   2.0000],\n",
      "        [125.2163, 254.5766, 188.3493, 322.7215,   0.9995,   0.9877,   2.0000],\n",
      "        [225.5808, 267.0677, 244.2433, 292.1075,   0.9681,   0.9821,   2.0000],\n",
      "        [255.7018, 266.6706, 272.3247, 286.9782,   0.9637,   0.9855,   2.0000],\n",
      "        [183.2204, 268.9752, 196.6883, 283.9675,   0.8934,   0.9990,   2.0000],\n",
      "        [202.7672, 263.8997, 219.1320, 286.2717,   0.9708,   0.9011,   2.0000]])]\n",
      "FPS of the video is 13.66\n",
      "[tensor([[ 1.1050e+02,  2.5495e+02,  1.8093e+02,  3.2838e+02,  9.9934e-01,\n",
      "          9.9834e-01,  2.0000e+00],\n",
      "        [-1.2151e-01,  2.5151e+02,  6.3182e+01,  3.3443e+02,  9.9731e-01,\n",
      "          9.7953e-01,  2.0000e+00],\n",
      "        [ 8.5863e+01,  2.5818e+02,  1.2533e+02,  3.0657e+02,  9.6226e-01,\n",
      "          9.9051e-01,  2.0000e+00],\n",
      "        [ 2.0404e+02,  2.6453e+02,  2.1990e+02,  2.8624e+02,  9.7684e-01,\n",
      "          9.6487e-01,  2.0000e+00],\n",
      "        [ 2.5377e+02,  2.6996e+02,  2.6707e+02,  2.8446e+02,  9.4020e-01,\n",
      "          9.9732e-01,  2.0000e+00],\n",
      "        [ 2.2590e+02,  2.6703e+02,  2.4423e+02,  2.9203e+02,  9.5704e-01,\n",
      "          9.7882e-01,  2.0000e+00],\n",
      "        [ 1.9081e+02,  2.6873e+02,  2.0035e+02,  2.8235e+02,  8.7810e-01,\n",
      "          9.9723e-01,  2.0000e+00],\n",
      "        [ 1.7602e+02,  2.6863e+02,  1.8900e+02,  2.8626e+02,  8.0362e-01,\n",
      "          9.9835e-01,  2.0000e+00]])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPS of the video is  5.85\n",
      "[tensor([[108.4131, 257.3834, 180.3452, 330.6579,   0.9972,   0.9967,   2.0000],\n",
      "        [ 55.0750, 262.1215, 115.9497, 315.9354,   0.9927,   0.9955,   2.0000],\n",
      "        [252.3196, 270.4709, 266.4370, 284.4019,   0.9739,   0.9985,   2.0000],\n",
      "        [225.6403, 266.8250, 244.1332, 292.2647,   0.9587,   0.9796,   2.0000],\n",
      "        [204.1886, 265.0894, 220.3957, 286.2959,   0.9726,   0.9638,   2.0000],\n",
      "        [172.0628, 269.7248, 188.1687, 286.6862,   0.8495,   0.9964,   2.0000]])]\n",
      "FPS of the video is 11.75\n",
      "[tensor([[ 52.2482, 258.2798, 109.2206, 318.0176,   0.9983,   0.9988,   2.0000],\n",
      "        [103.3222, 254.9913, 177.7475, 330.7126,   0.9998,   0.9928,   2.0000],\n",
      "        [251.2337, 269.7424, 265.8298, 283.9448,   0.9847,   0.9973,   2.0000],\n",
      "        [226.0137, 267.3205, 243.6996, 291.6297,   0.9579,   0.9832,   2.0000],\n",
      "        [174.2040, 267.6449, 188.5639, 286.6794,   0.8575,   0.9946,   2.0000],\n",
      "        [204.5783, 262.8850, 219.5332, 285.9009,   0.9598,   0.8036,   2.0000]])]\n",
      "FPS of the video is  5.76\n",
      "[tensor([[ 96.4055, 253.8393, 172.6995, 335.7591,   0.9999,   0.9968,   2.0000],\n",
      "        [  5.4952, 251.7414,  94.2383, 329.0127,   0.9995,   0.9965,   2.0000],\n",
      "        [250.9904, 268.6028, 265.1741, 283.5967,   0.9826,   0.9970,   2.0000],\n",
      "        [167.7307, 267.2402, 184.8716, 289.2091,   0.9788,   0.9867,   2.0000],\n",
      "        [226.0987, 267.4191, 243.6017, 291.6033,   0.9570,   0.9819,   2.0000],\n",
      "        [204.3264, 263.4597, 219.8480, 285.5519,   0.9391,   0.7377,   2.0000]])]\n"
     ]
    }
   ],
   "source": [
    "frames = 0\n",
    "start = time.time()\n",
    "\n",
    "# ret_val, img = cam.read()\n",
    "# img_size = img.shape[:2]\n",
    "\n",
    "while True:\n",
    "    ret_val, img = cam.read()\n",
    "    # img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    # Mirror \n",
    "    img = cv2.flip(img, 1)\n",
    "    img_re = cv2.resize(img, (416, 416))\n",
    "    \n",
    "    input_imgs = transforms.ToTensor()(img_re)\n",
    "    input_imgs = torch.unsqueeze(input_imgs, 0).to(device)\n",
    "\n",
    "    # Get detections\n",
    "    with torch.no_grad():\n",
    "        detections = model(input_imgs)\n",
    "        detections = non_max_suppression(detections, opt.conf_thres, opt.nms_thres)\n",
    "        img_detections.extend(detections)\n",
    "    \n",
    "    # Create plot\n",
    "    # Draw bounding boxes and labels of detections\n",
    "    if detections[0] is not None:\n",
    "        # Rescale boxes to original image\n",
    "#         detections = rescale_boxes(detections[0], opt.img_size, img.shape[:2])\n",
    "\n",
    "        for x1, y1, x2, y2, conf, cls_conf, cls_pred in detections[0]:\n",
    "            plot_one_box((x1,y1,x2,y2), img_re, label=classes[int(cls_pred)])\n",
    "    \n",
    "    frames += 1\n",
    "    intv = time.time() - start\n",
    "    if intv > 1:\n",
    "        print(\"FPS of the video is {:5.2f}\".format( frames / intv ))\n",
    "        print(detections)\n",
    "        start = time.time()\n",
    "        frames = 0\n",
    "    \n",
    "    cv2.imshow('Demo webcam', img_re)\n",
    "    if cv2.waitKey(0) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
